import streamlit as st
import requests
import numpy as np
import plotly.express as px

# FastAPI Backend URL
FASTAPI_URL = "http://localhost:8000"

# ------------------------- SIDEBAR -------------------------
st.sidebar.title("ğŸ”§ RAG Application Settings")

# File Upload
uploaded_file = st.sidebar.file_uploader("ğŸ“‚ Upload a file", type=["pdf", "txt", "md"])

# Chunking Method
chunking_method = st.sidebar.selectbox(
    "ğŸ” Choose Chunking Method", ["Fixed Size", "Semantic", "Recursive"]
)

# Embedding Model Selection
embedding_model = st.sidebar.selectbox(
    "ğŸ§  Choose Embedding Model", ["OpenAI", "Cohere", "Hugging Face"]
)

# LLM Model Selection
llm_model = st.sidebar.selectbox(
    "ğŸ¤– Choose LLM Model", ["GPT-4 (OpenAI)", "Command R+ (Cohere)"]
)

# Process Button
if st.sidebar.button("ğŸš€ Process File"):
    if uploaded_file:
        files = {"file": uploaded_file.getvalue()}
        response = requests.post(f"{FASTAPI_URL}/upload", files=files)
        if response.status_code == 200:
            st.sidebar.success("âœ… File uploaded and processed successfully!")
        else:
            st.sidebar.error("âŒ Upload failed.")
    else:
        st.sidebar.warning("âš  Please upload a file first.")

# ------------------------- MAIN CONTENT -------------------------

st.title("ğŸ“– RAG (Retrieval-Augmented Generation) Playground")

# 1ï¸âƒ£ File Preview & Chunking
st.subheader("ğŸ“œ File Preview & Chunking")

if uploaded_file:
    file_contents = uploaded_file.getvalue().decode("utf-8")
    st.text_area("File Content", file_contents[:2000], height=200)

    if st.button("ğŸ”¹ Chunk Document"):
        response = requests.post(
            f"{FASTAPI_URL}/chunk",
            json={"method": chunking_method},
        )
        if response.status_code == 200:
            st.success(f"âœ… Document chunked using {chunking_method}")
            chunks = response.json().get("chunks", [])
            for i, chunk in enumerate(chunks[:5]):  # Show first 5 chunks
                st.write(f"ğŸ”¹ **Chunk {i+1}:** {chunk}")
        else:
            st.error("âŒ Chunking failed.")

# 2ï¸âƒ£ Embedding Visualization
st.subheader("ğŸ“Š Embedding Visualization")

if st.button("ğŸ§  Generate Embeddings"):
    response = requests.post(
        f"{FASTAPI_URL}/generate-embeddings",
        json={"model": embedding_model},
    )
    if response.status_code == 200:
        st.success(f"âœ… Embeddings generated using {embedding_model}")
        
        # Fake embedding data for testing
        embeddings = np.random.rand(10, 3)
        df = {"x": embeddings[:, 0], "y": embeddings[:, 1], "z": embeddings[:, 2]}

        fig = px.scatter_3d(df, x="x", y="y", z="z", title="Embedding Space")
        st.plotly_chart(fig)
    else:
        st.error("âŒ Embedding generation failed.")

# 3ï¸âƒ£ LLM Response Generation
st.subheader("ğŸ¤– Ask Your Document")

query = st.text_input("ğŸ’¬ Enter your question:")
if st.button("ğŸ“ Generate Response"):
    response = requests.post(
        f"{FASTAPI_URL}/generate-response",
        json={"query": query, "model": llm_model},
    )
    if response.status_code == 200:
        answer = response.json().get("answer", "No response generated.")
        st.write("ğŸ’¬ **User:**", query)
        st.write("ğŸ§  **AI:**", answer)
    else:
        st.error("âŒ Response generation failed.")
